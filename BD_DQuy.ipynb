{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu từ tập tin CSV\n",
    "import pandas as pd\n",
    "# Đường dẫn đến tập tin CSV\n",
    "#file_path = 'C:\\\\Users\\\\LG\\\\Desktop\\\\BD_DQ\\\\data_dotquy.csv'\n",
    "#file_path = 'C:\\\\Users\\\\Admin\\\\Desktop\\\\BD_DQ\\\\data_dotquy.csv'\n",
    "file_path = 'C:\\\\Users\\\\ACER\\\\Desktop\\\\BD_DQ\\\\data_dotquy.csv'#Hien\n",
    "# Đọc dữ liệu từ CSV vào DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "# Hiển thị DataFrame trong VS Code\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LÀM SẠCH và CHUẨN HÓA DL\n",
    "- 1 giới tính: loại other\n",
    "- 2 tuổi: Loại số thực ( vd: 0.1 , 1.56) rồi dùng kỹ thuật Age Grouping\n",
    "- 3 Đã kết hôn: chuyển về 0 và một\n",
    "- 4 kiểu làm việc(work_type)\n",
    "    + kỹ thuật Hashing Encoding\n",
    "    + kỹ thuật One-Hot Encoding\n",
    "- 5 vùng sống: chuyển về 0 và một\n",
    "- 6 BMI  \n",
    "    + Loại bỏ các hàng hoặc cột có N/A rồi dùng kỹ thuật Binary Encoding\n",
    "    + dùng kỹ thuật Simple Imputation rồi dùng kỹ thuật tiếp Min-Max Scaling\n",
    "- 7 smoking_status\n",
    "  + Loại bỏ các hàng hoặc cột có Unknown rồi dùng kỹ thuật tiếp Min-Max Scaling\n",
    "  + kỹ thuật Frequency Encoding\n",
    "- 8 avg_glucose_level (mg/dL)\n",
    "    DÙNG KỸ THUẬT: Min-Max Scaling\n",
    "  ******ĐIỀU KIỆN LÀ******\n",
    "    Người bình thường:\n",
    "     < 140\n",
    "    Người Bị tiểu đường:\n",
    "      >=140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hien\n",
    "#Kiem tra trung lap\n",
    "duplicated_rows = df[df.duplicated(subset='id')]\n",
    "print(\"So luong du lieu trung lap la:\" , len(duplicated_rows))\n",
    "\n",
    "#df = df.dropna()\n",
    "#df = df.applymap(lambda x: x.replace(\"\\n\",\" \") if isinstance(x, str) else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hien\n",
    "#Kiểm tra dữ liệu có bị thiếu\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hien\n",
    "# dùng knn điền dữ liệu thiếu vào BMI\n",
    "# Tạo đối tượng KNN Imputer với số lượng hàng xóm là 3\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# Áp dụng imputer cho DataFrame, chỉ chọn các cột số\n",
    "df[['age', 'bmi']] = imputer.fit_transform(df[['age', 'bmi']])\n",
    "\n",
    "# Hiển thị DataFrame sau khi điền dữ liệu\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra lại đã dủ dữ liệu chưa\n",
    "df['bmi'].isnull().sum()\n",
    "df['bmi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hien\n",
    "# Xóa cột mã định danh\n",
    "df  = df.drop(columns=['id'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chau_Muc1\n",
    "#Loại bỏ giới tính mang giá trị Other\n",
    "mask = df['gender'].isin(['Male', 'Female'])\n",
    "df = df[mask]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chau_Muc1\n",
    "# gender: female 1 male 0\n",
    "df.loc[:, 'gender'] = df['gender'].replace({'Female': 1, 'Male': 0})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chau_Muc5(Phần này phân công cho GIANG)\n",
    "# Residence_type: urban 1 rural 0(can note)\n",
    "#df.loc[:, 'Residence_type'] = df['Residence_type'].replace({'Urban': 1, 'Rural': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chau_Muc4(Phần này lấy code của bạn GIANG)\n",
    "#chuẩn hóa dữ liệu field work_type theo kỹ thuật label encoding\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#le=LabelEncoder()\n",
    "#df.loc[:, 'work_type'] = le.fit_transform(df['work_type'])\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi_Muc2\n",
    "# Kiểm tra xem tuổi có phải là số nguyên hay không\n",
    "df['Is_Whole_Number'] = df['age'].apply(lambda x: x.is_integer())\n",
    "\n",
    "# Lọc các hàng mà tuổi không phải là số thực (chỉ giữ lại số nguyên)\n",
    "df = df[df['Is_Whole_Number']]\n",
    "\n",
    "# Xóa cột tạm thời 'Is_Whole_Number'\n",
    "df = df.drop(columns=['Is_Whole_Number'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi_Muc2\n",
    "# Chuẩn hóa bằng Min-Max Scaling\n",
    "# Calculate min and max values\n",
    "X_min = min(df['age'])\n",
    "X_max = max(df['age'])\n",
    "\n",
    "# Apply Min-Max Scaling\n",
    "scaled_data = [(x - X_min) / (X_max - X_min) for x in df['age']]\n",
    "\n",
    "# Gán lại dữ liệu vào cột ['avg_glucose_level']\n",
    "df['age'] = scaled_data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi(điều chỉnh tuổi về min max)\n",
    "# Định nghĩa các khoảng tuổi và các nhãn cho các nhóm tuổi\n",
    "#bins = [0, 18, 35, 60, 100]\n",
    "#labels = ['0', '1', '2', '3']\n",
    "\n",
    "# Chia cột \"Age\" thành các nhóm tuổi\n",
    "#df['Age Group'] = pd.cut(df['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi_Muc3\n",
    "#Chuyen trạng thái đã kết hôn về dạng 1 và chưa kết hôn về dạng 0\n",
    "df['ever_married'] = df['ever_married'].map({'Yes': 1, 'No': 0})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Giang_Muc4(Gán thẳng giá trị vào work_type)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['work_type'] = label_encoder.fit_transform(df['work_type'])\n",
    "\n",
    "# sử dụng chuẩn hóa bằng Min-Max Scaling chuan hoa df['work_type'] dang (0 1 2 3 4)\n",
    "# Calculate min and max values\n",
    "X_min = min(df['work_type'])\n",
    "X_max = max(df['work_type'])\n",
    "\n",
    "# Apply Min-Max Scaling\n",
    "scaled_data = [(x - X_min) / (X_max - X_min) for x in df['work_type']]\n",
    "scaled_data\n",
    "# Tạo ra trường dữ liệu mới work_type_2\n",
    "df['work_type'] =scaled_data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Giang_Muc5\n",
    "# Chuyen trạng thái thành thị về dạng 1 và nông thôn về dạng 0\n",
    "df['Residence_type']=df['Residence_type'].replace({'Urban':1,'Rural':0})\n",
    "mask = df['gender'] != 'Other'\n",
    "df_filtered = df[mask]\n",
    "print(df_filtered) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hien_Mục6\n",
    "# chuẩn hóa bằng Min-Max Scaling\n",
    "glucose_values = df['avg_glucose_level']\n",
    "\n",
    "# Calculate min and max values\n",
    "X_min = min(df['avg_glucose_level'])\n",
    "X_max = max(df['avg_glucose_level'])\n",
    "\n",
    "# Apply Min-Max Scaling\n",
    "scaled_data = [(x - X_min) / (X_max - X_min) for x in df['avg_glucose_level']]\n",
    "\n",
    "# Gán lại dữ liệu vào cột ['avg_glucose_level']\n",
    "df['avg_glucose_level'] = scaled_data\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hoang_Muc7\n",
    "# Dữ liệu ban đầu\n",
    "data = df['bmi']\n",
    "\n",
    "# Min-Max Scaling\n",
    "data_min = data.min()\n",
    "data_max = data.max()\n",
    "\n",
    "scaled_data = (data - data_min) / (data_max - data_min)\n",
    "\n",
    "# Hiển thị dữ liệu đã chuẩn hóa\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hoang_Muc7\n",
    "df['bmi']=scaled_data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hoang_Muc7\n",
    "# Dữ liệu ban đầu\n",
    "data = df['bmi']\n",
    "\n",
    "# Chuyển đổi dữ liệu thành DataFrame\n",
    "dff = pd.DataFrame(data, columns=['bmi'])\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hoang_Muc7\n",
    "#import numpy as np\n",
    "#conditions = [\n",
    "   # (dff['bmi'] < 18.5),\n",
    "  #  (dff['bmi'] >= 18.5) & (dff['bmi'] <= 25),\n",
    "    #(dff['bmi'] > 25)\n",
    "#]\n",
    "\n",
    "# Các giá trị tương ứng cho mỗi điều kiện\n",
    "#df['underweight'] = np.where(dff['bmi'] < 18.5, 1, 0)\n",
    "#df['normal'] = np.where((dff['bmi'] >= 18.5) & (dff['bmi'] <= 25), 1, 0)\n",
    "#df['overweight'] = np.where(dff['bmi'] > 25, 1, 0)\n",
    "\n",
    "# Hiển thị DataFrame với dữ liệu đã chuẩn hóa\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binh_Muc8\n",
    "df.dropna(how='all', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binh_Muc8\n",
    "df = df[df['smoking_status'] != 'Unknown']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binh_Muc8\n",
    "map_smoking_status = {\n",
    "    'never smoked': 0,\n",
    "    'formerly smoked': 0.5,\n",
    "    'smokes': 1\n",
    "}\n",
    "\n",
    "df['smoking_status'] = df['smoking_status'].map(map_smoking_status)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hien\n",
    "#Trực quan hóa dữ liệu bằng biểu đồ nhiệt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "corr = df.corr()\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.title(\"Bảng tương quan các thuộc tính\", frontsize = 16)\n",
    "# sns.heatmap(corr, annot= True, cmap=\"Blues\")\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title(\"Bảng tương quan các thuộc tính\", fontsize=16)\n",
    "sns.heatmap(corr, annot=True, cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CÂN BẰNG DỮ LIỆU Ở CỘT \"STROKE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hien\n",
    "# Kết hợp cả Oversampling và Undersampling để cân bằng dữ liệu \n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Tách dữ liệu thành các biến đặc trưng (X) và biến mục tiêu (y)\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df['stroke']\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tạo các đối tượng Oversampling và Undersampling\n",
    "over = SMOTE(sampling_strategy=0.5, random_state=42)  # Tăng cường lớp thiểu số\n",
    "under = RandomUnderSampler(sampling_strategy=0.8, random_state=42)  # Giảm lớp chiếm ưu thế\n",
    "\n",
    "# Tạo Pipeline kết hợp Oversampling và Undersampling\n",
    "pipeline = Pipeline(steps=[('o', over), ('u', under)])\n",
    "\n",
    "# Áp dụng pipeline trên dữ liệu huấn luyện\n",
    "X_resampled, y_resampled = pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "# Kiểm tra kích thước của dữ liệu sau khi cân bằng\n",
    "print(\"Kích thước dữ liệu huấn luyện sau khi cân bằng:\")\n",
    "print(f\"X_resampled: {X_resampled.shape}\")\n",
    "print(f\"y_resampled: {y_resampled.shape}\")\n",
    "\n",
    "# Xem số lượng mẫu trong mỗi lớp sau khi cân bằng\n",
    "print(\"Số lượng mẫu trong từng lớp sau khi cân bằng:\")\n",
    "print(y_resampled.value_counts())\n",
    "\n",
    "# Kết hợp lại X_resampled và y_resampled để tạo thành một DataFrame hoàn chỉnh\n",
    "df = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "df['stroke'] = y_resampled\n",
    "\n",
    "# Xem trước dữ liệu sau khi cân bằng\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xem số người bị đột quỵ trong bảng\n",
    "dfff = df[df['stroke'] == 1]\n",
    "print(\"Số người bị đột quỵ là \" ) \n",
    "len(dfff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xem số người KHÔNG bị đột quỵ trong bảng\n",
    "dfff = df[df['stroke'] == 0]\n",
    "print(\"Số người KHÔNG bị đột quỵ là \" ) \n",
    "len(dfff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XÂY DỰNG MÔ HÌNH HỌC MÁY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chau muc_2\n",
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "X = df[['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status']]\n",
    "y = df['stroke']\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "x=df.drop(['stroke'],axis=1)\n",
    "y=df['stroke']\n",
    "de_model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "y_pred = de_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Độ chính xác của mô hình Decision Tree là: \", de_model.score(X_test, y_test)*100,\"%\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(de_model, x_data, y_data):\n",
    "    # Tính toán dự đoán\n",
    "    y_pred = de_model.predict(x_data)\n",
    "    # Lấy các nhãn duy nhất\n",
    "    labels = np.unique(y_data)\n",
    "    # Tính toán ma trận nhầm lẫn\n",
    "    cm = confusion_matrix(y_data, y_pred, labels=labels)\n",
    "    # Vẽ ma trận nhầm lẫn\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='pink', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Nhãn dự đoán')\n",
    "    plt.ylabel('Nhãn thực tế')\n",
    "    plt.title('Ma trận nhầm lẫn')\n",
    "    plt.show()\n",
    "\n",
    "# Gọi hàm plot_confusion_matrix với mô hình logistic_model, dữ liệu x_train và nhãn y_train\n",
    "plot_confusion_matrix(de_model, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chau_muc2\n",
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X = df[['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status']]\n",
    "y = df['stroke']\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Khởi tạo mô hình Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "# Tạo lưới tham số để tìm kiếm\n",
    "param_dist = {'n_estimators': [100, 200, 300],'max_depth': [5, 10, 15, None],'min_samples_split': [2, 5, 10],'min_samples_leaf': [1, 2, 4],'bootstrap': [True, False]}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=100, cv=5)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Tạo mô hình với siêu tham số tốt nhất\n",
    "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "# Huấn luyện mô hình\n",
    "best_rf.fit(X_train, y_train)\n",
    "# Dự đoán trên tập kiểm tra\n",
    "y_pred = best_rf.predict(X_test)\n",
    "# Đánh giá mô hình\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Độ chính xác của mô hình Random Forest là: \", best_rf.score(X_test, y_test)*100,\"%\")\n",
    "# Vẽ ma trận nhầm lẫn\n",
    "def plot_confusion_matrix(best_rf, X_test, y_test):\n",
    "    # Dự đoán trên tập kiểm tra\n",
    "    y_pred = best_rf.predict(X_test)\n",
    "    # Tính toán ma trận nhầm lẫn\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    # Vẽ biểu đồ\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "    plt.xlabel('Nhãn dự đoán')\n",
    "    plt.ylabel('Nhãn thực tế')\n",
    "    plt.title('Ma trận nhầm lẫn')\n",
    "    plt.show()\n",
    "# Gọi hàm để vẽ ma trận nhầm lẫn\n",
    "plot_confusion_matrix(best_rf, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chau_muc2\n",
    "#vẽ features importance\n",
    "import matplotlib.pyplot as plt\n",
    "# Quan trọng tính của các đặc trưng\n",
    "importances = best_rf.feature_importances_\n",
    "data =pd.DataFrame( {'feature': ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status'],'importance': best_rf.feature_importances_} )\n",
    "# Sắp xếp theo thứ tự giảm dần của quan trọng tính\n",
    "data = data.sort_values('importance', ascending=False)\n",
    "print (data)\n",
    "# Vẽ biểu đồ cột\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(data['feature'], data['importance'])\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Features Importances')\n",
    "# Đảo ngược trục y để đặc trưng quan trọng nhất ở trên\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Giang_Muc2\n",
    "\n",
    "#import thu vien\n",
    "import numpy as np\n",
    "import seaborn as sns # mở cmd cài:  pip install seaborn\n",
    "import matplotlib.pyplot as plt # mở cmd cài:  pip install matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Train căn bản\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# clf = LogisticRegression(random_state= 10000)\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# #Dự đoán\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# # Dự đoán trên tập dữ liệu kiểm thử\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# # In báo cáo phân loại\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chi\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Giả sử df là DataFrame chứa dữ liệu của bạn\n",
    "X = df[['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status']]\n",
    "y = df['stroke']\n",
    "\n",
    "# Tăng cường dữ liệu bằng SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Khởi tạo mô hình Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Tạo lưới tham số để tìm kiếm\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Sử dụng GridSearchCV để tìm kiếm siêu tham số tốt nhất\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Tạo mô hình với siêu tham số tốt nhất\n",
    "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Độ chính xác của mô hình Random Forest là: \", best_rf.score(X_test, y_test)*100, \"%\")\n",
    "\n",
    "# Vẽ ma trận nhầm lẫn\n",
    "def plot_confusion_matrix(best_rf, X_test, y_test):\n",
    "    # Dự đoán trên tập kiểm tra\n",
    "    y_pred = best_rf.predict(X_test)\n",
    "    # Tính toán ma trận nhầm lẫn\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    # Vẽ biểu đồ\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "    plt.xlabel('Nhãn dự đoán')\n",
    "    plt.ylabel('Nhãn thực tế')\n",
    "    plt.title('Ma trận nhầm lẫn')\n",
    "    plt.show()\n",
    "\n",
    "# Gọi hàm để vẽ ma trận nhầm lẫn\n",
    "plot_confusion_matrix(best_rf, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chi\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from skopt import BayesSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Giả sử df là DataFrame chứa dữ liệu của bạn\n",
    "X = df[['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status']]\n",
    "y = df['stroke']\n",
    "\n",
    "# Tăng cường dữ liệu bằng SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Khởi tạo mô hình Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Sử dụng Bayesian Optimization để tìm kiếm siêu tham số tốt nhất\n",
    "param_dist = {\n",
    "    'n_estimators': (100, 1000),\n",
    "    'max_depth': (5, 50),\n",
    "    'min_samples_split': (2, 10),\n",
    "    'min_samples_leaf': (1, 4),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "bayes_search = BayesSearchCV(estimator=rf, search_spaces=param_dist, n_iter=100, cv=5, n_jobs=-1, scoring='accuracy', random_state=42)\n",
    "bayes_search.fit(X_train, y_train)\n",
    "best_params = bayes_search.best_params_\n",
    "\n",
    "# Tạo mô hình với siêu tham số tốt nhất\n",
    "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Độ chính xác của mô hình Random Forest là: \", best_rf.score(X_test, y_test)*100, \"%\")\n",
    "\n",
    "# Vẽ ma trận nhầm lẫn\n",
    "def plot_confusion_matrix(best_rf, X_test, y_test):\n",
    "    # Dự đoán trên tập kiểm tra\n",
    "    y_pred = best_rf.predict(X_test)\n",
    "    # Tính toán ma trận nhầm lẫn\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    # Vẽ biểu đồ\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "    plt.xlabel('Nhãn dự đoán')\n",
    "    plt.ylabel('Nhãn thực tế')\n",
    "    plt.title('Ma trận nhầm lẫn')\n",
    "    plt.show()\n",
    "\n",
    "# Gọi hàm để vẽ ma trận nhầm lẫn\n",
    "plot_confusion_matrix(best_rf, X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
